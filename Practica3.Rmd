---
title: "Practica3"
author: "PEDRO SANCHEZ"
date: "2024-05-22"
output: html_document
editor_options: 
  markdown: 

    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# PRÁCTICA 3

## ANÁLISIS DE LOGS DE SERVIDOR USANDO R (PARTE II)

###Obtención y carga de los Datos

### 1. Descomprimir el fichero comprimido que contiene los registros del servidor, y a partir de los datos extraídos, cargar en data frame los registros con las peticiones servidas.

Cargar las librerías

```{r carga_libreria}
#install.packages("httr")
#install.packages("XML")
#install.packages("stringr")
#install.packages("readr")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("mltools")
#install.packages("data.table")
#install.packages("stats")

library(httr)
library(XML)
library(dplyr)
library(stringr)
library(readr)
library(ggplot2)
library(mltools)
library(data.table)
library(stats)
library(mltools)
```

Cargar la data

```{r carga_datos_3, echo=FALSE}
library(readr)
epa_http <- read_table("D:/epa-http.csv", 
    col_names = FALSE)
View(epa_http)
```

### 2. Incluid en el documento un apartado con la descripción de los datos analizados: fuente, tipología, descripción de la información contenida (los diferentes campos) y sus valores.

A continuación se detalla el significado de las columnas del data frame "epa_http":

- Request
- timestamp
- petition
- URL
- protocol
- response_code 
- bytes_reply

200	Correcto acceso
302	Ha sido modivo temporalmente
304	Recurso no ha sido modificado desde último acceso
400	No procesa solicitud por error de cliente
403	Acceso a página esta restringido
404	La URL ingresada no esta disponible
500	Error interno de servidor
501	Servidor no responde solicitud de cliente

###Limpieza de los Datos

### 3. Aprovechando que los datos a analizar son los mismos de la primera práctica, para esta entrega es imprescindible que los datos estén en formato de “datos elegantes”.

Para un mejor entendimiento de la informaciòn, se procede a cambiar los nombres de las cabeceras del dataSet epa_http a "Request", "timestamp", "petition", "URL", "protocol", "response_code" y "bytes_reply"

```{r ver_cabeceras}
names(epa_http) <- c("Request", "timestamp", "petition", "URL", "protocol", "response_code", "bytes_reply")
epa_http
```

Tras el anàlisis de la informaciòn, se ha encontrado data vacìa y con el signo "-". se renombra y se cambia a null a continuaciòn:

```{r ver_null}
epa_http[is.na(epa_http)] <- "null"
epa_http[epa_http == "-"] <- "null"
epa_http
```

Se procede a quitar el signo comillas que inicia y termina en los valores de las columnas "petition" y "protocol"

```{r quitar_comillas}
# Usar mutate() de dplyr junto con gsub()
epa_http <- epa_http %>%
  mutate(
    petition = gsub('"', '', petition),
    protocol = gsub('"', '', protocol))
```

```{r convertir_caracter_numeric}
# Inicializar los valores nulos en la columna "bytes_reply" con 0
epa_http$bytes_reply[is.na(epa_http$bytes_reply)] <- 0

# Convertir la columna "bytes_reply" a tipo numérico
  epa_http$bytes_reply <- as.numeric(epa_http$bytes_reply)
  
  unique_values <- unique(epa_http$bytes_reply)
  print(unique_values)
  
```

Se procede convertir la columna 'timestamp' a formato de fecha y hora:
```{r convertir_fecha}
epa_http$timestamp <- as.POSIXct(epa_http$timestamp, format = "[%d:%H:%M:%S]")
epa_http
```
###Exploración de Datos

### 4. Identificar el número único de usuarios que han interactuado directamente con el servidor de forma segregada según si los usuarios han tenido algún tipo de error en las distintas peticiones ofrecidas por el servidor.

```{r usuarios_interactuan_servidor}
# Filtrar interacciones que han encontrado errores
interactions_with_errors <- epa_http %>%
  filter(response_code >= 400 & response_code < 600)

# Identificar URLs únicas con errores
unique_urls_with_errors <- distinct(interactions_with_errors, URL)

# Filtrar interacciones que no han encontrado errores
interactions_without_errors <- epa_http %>%
  filter(response_code < 400)

# Identificar URLs únicas sin errores
unique_urls_without_errors <- distinct(interactions_without_errors, URL)

# Contar el número de usuarios por URLs únicas que han encontrado errores
num_urls_with_errors <- nrow(unique_urls_with_errors)

# Contar el número de usuarios por URLs únicas que no han encontrado errores
num_urls_without_errors <- nrow(unique_urls_without_errors)


# Identificar los distintos tipos de errores
error_types <- unique(epa_http$response_code[epa_http$response_code >= 400 & epa_http$response_code < 600])

# Filtrar los errores y contar el número de interacciones únicas por tipo de error
error_summary <- epa_http %>%
  filter(response_code >= 400 & response_code < 600) %>%
  group_by(response_code) %>%
  summarise(unique_interactions = n_distinct(URL))
print(error_summary)

```

Lo que se visualizo en la información anterior, filtran los errores y se cuenta el número de interacciones únicas por tipo de error.

El número de usuarios con interacciones únicas que han encontrado errores son `r num_urls_with_errors`

El número de usuarios con interacciones únicas que no han encontrado errores son `r num_urls_without_errors`

Se identifican los distintos tipos de errores que son lo siguientes: `r error_types`

### Análisis de Datos

### 5. Analizar los distintos tipos de peticiones HTTP (GET, POST, PUT, DELETE) gestionadas por el servidor, identificando la frecuencia de cada una de estas. Repetir el análisis, esta vez filtrando previamente aquellas peticiones correspondientes a recursos ofrecidos de tipo imagen.

```{r analisis_peticiones}
# Contar la frecuencia de cada tipo de petición HTTP
petition_summary <- epa_http %>%
  group_by(petition) %>%
  summarise(frequency = n())

print(petition_summary)

# Filtrar peticiones a recursos de tipo imagen
image_requests <- epa_http %>%
  filter(grepl("\\.(gif|jpg|jpeg|png)$", URL, ignore.case = TRUE))

# Contar la frecuencia de cada tipo de petición HTTP para recursos de tipo imagen
image_petition_summary <- image_requests %>%
  group_by(petition) %>%
  summarise(frequency = n())

print(image_petition_summary)

```
###Visualización de Resultados

### 6. Generar al menos 2 gráficos distintos que permitan visualizar alguna característica relevante de los datos analizados.

```{r analisis_graficos}

# Contar la frecuencia de cada tipo de petición HTTP
petition_summary <- epa_http %>%
  group_by(petition) %>%
  summarise(frequency = n())

# Filtrar peticiones a recursos de tipo imagen
image_requests <- epa_http %>%
  filter(grepl("\\.(gif|jpg|jpeg|png)$", URL, ignore.case = TRUE))

# Contar la frecuencia de cada tipo de petición HTTP para recursos de tipo imagen
image_petition_summary <- image_requests %>%
  group_by(petition) %>%
  summarise(frequency = n())

# Crear el gráfico de barras
ggplot(petition_summary, aes(x = petition, y = frequency, fill = petition)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = frequency), position = position_stack(vjust = 0.5), color = "black", size = 5) + 
  # Colocar las cantidades encima de las barras
  labs(title = "Frecuencia de Tipos de Petición HTTP", x = "Tipo de Petición", y = "Frecuencia") +
  theme_minimal() +
  theme(legend.position = "none")


# Crear el gráfico de pastel con etiquetas fuera del círculo
ggplot(image_petition_summary, aes(x = "", y = frequency, fill = petition)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y") +
  geom_text(aes(label = paste0(frequency, "\n(", petition, ")")), 
            position = position_stack(vjust = 0.5), color = "white", size = 3, 
            angle = 0, hjust = 1.25) + # Colocar las cantidades fuera del círculo del pastel
  geom_text(aes(label = paste0(frequency, "\n(", petition, ")")), 
            position = position_stack(vjust = 0.5), color = "black", size = 3, 
            angle = 0, hjust = 1.25, check_overlap = TRUE) + # Dispersar las etiquetas y evitar superposiciones
  theme_void() +
  theme(legend.position = "right")

```

### 7. Generar un gráfico que permita visualizar el número de peticiones servidas a lo largo del tiempo.

```{r grafico_2}

# Crear un gráfico de líneas que muestre el número de peticiones servidas a lo largo del tiempo
ggplot(epa_http, aes(x = timestamp)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  scale_x_datetime(date_labels = "%Y-%m", date_breaks = "1 month") +
  labs(title = "Número de Peticiones Servidas a lo Largo del Tiempo", x = "Fecha", y = "Número de Peticiones") +
  theme_minimal()

```

## Clústering de datos


### 8. Utilizando un algoritmo de aprendizaje no supervisado, realizad un análisis de clústering con k-means para los datos del servidor.


```{r Clustering_1}

# Paso 1: Crear una columna numérica derivada del número de caracteres de la URL
epa_http$URL_length <- nchar(epa_http$URL)

# Paso 2: Convertir columnas factor a columnas numéricas utilizando one_hot
epa_http_one_hot <- one_hot(as.data.table(epa_http), sparsifyNAs = TRUE)

# Paso 3: Descartar columnas que no sean numéricas
epa_http_numeric <- epa_http_one_hot[, sapply(epa_http_one_hot, is.numeric), with = FALSE]

# Paso 4: Imputar valores faltantes en la columna 'bytes_reply'
epa_http$bytes_reply[is.na(epa_http$bytes_reply) & epa_http$response_code == 404] <- 0

# Paso 5: Realizar análisis de clustering con k-means para diferentes valores de k
set.seed(123)  # Establecer una semilla para reproducibilidad
k_values <- c(3, 5)  # Ejemplo de diferentes valores de k
clustering_results <- lapply(k_values, function(k) kmeans(epa_http_numeric, centers = k))

#
# Respuesta de la pregunta 9 hacia abajo:
#

# Añadir los clústeres al dataframe original
epa_http$cluster_k3 <- clustering_results[[1]]$cluster
epa_http$cluster_k5 <- clustering_results[[2]]$cluster

# Paso 6: Visualizar los resultados de clustering con scatter plots

# Scatter plot para k = 3
plot_k3 <- ggplot(epa_http, aes(x = bytes_reply, y = URL_length, color = factor(cluster_k3))) +
  geom_point() +
  labs(title = "Clustering con k = 3", x = "Bytes Reply", y = "URL Length", color = "Cluster") +
  theme_minimal()

# Scatter plot para k = 5
plot_k5 <- ggplot(epa_http, aes(x = bytes_reply, y = URL_length, color = factor(cluster_k5))) +
  geom_point() +
  labs(title = "Clustering con k = 5", x = "Bytes Reply", y = "URL Length", color = "Cluster") +
  theme_minimal()

# Mostrar los gráficos
print(plot_k3)
print(plot_k5)

# Paso 7: Interpretar los resultados
# Para interpretar los resultados, podrías mostrar los primeros X casos de cada clúster y observar sus características.
head(epa_http[epa_http$cluster_k3 == 1,])
head(epa_http[epa_http$cluster_k3 == 2,])
head(epa_http[epa_http$cluster_k3 == 3,])

head(epa_http[epa_http$cluster_k5 == 1,])
head(epa_http[epa_http$cluster_k5 == 2,])
head(epa_http[epa_http$cluster_k5 == 3,])
head(epa_http[epa_http$cluster_k5 == 4,])
head(epa_http[epa_http$cluster_k5 == 5,])

```


```
